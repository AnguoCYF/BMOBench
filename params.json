{
  "name": "BMOBench",
  "tagline": "Black-Box Multi-Objective Optimization Benchmarking Platform",
  "body": "In this platform, we address **multi-objective optimization(minimization) problem**:\r\n\r\n#### \r\n\r\nSeveral algorithms/techniques have been proposed and studied to solve\r\nsuch problems. With this context, these algorithms are assessed in one\r\nof two ways, viz. theoretical, and empirical analysis. In theoretical\r\nanalysis, a principled methodology is carried out to derive an\r\nanalytical bound of the (run-time) solution quality. After t\r\nevaluations/steps, the quality of the returned solution is evaluated by\r\na loss/regret measure.\r\n\r\n#### \r\n\r\nAlternatively, empirical analysis employs experimental simulations of\r\nthe algorithm on complex problems, gaining an insight on the algorithm’s\r\npracticality/applicability on real-world problems. With this regard,\r\nmost of the time, methods proposed to solve MOPs are benchmarked on a\r\ndifferent set of problems under arbitrary budgets of function\r\nevaluation. We are interested in empirically assessing published/novel\r\nmulti-objective optimization algorithms in a unified (constantly\r\nupdated) framework.\r\n\r\n#### \r\n\r\nWe invite the multi-objective community to test their published/novel\r\nalgorithms in solving 100 MOPs reported in the literature\r\nwhere the feasible decision space has simple bound constraints, i.e.,\r\nproblems for which X=[l,u] and\r\nl<u. The benchmark validates the efficacy of the\r\nalgorithms by computing several quality indicators which are reported in\r\nterms of data profiles.\r\n\r\n### IMPORTANT DATES\r\n\r\n* Paper Submission Deadline: *15 August 2016*\r\n* Notification of Acceptance: *12 September 2016*\r\n* Final Paper Submission Deadline: *10 October 2016*\r\n\r\n### Brief Description\r\n* For a brief description of the platform and its experimental setup, please refer to [this report](http://arxiv.org/pdf/1605.07009v1.pdf).\r\n\r\n### Paper Submission:\r\n* Please follow IEEE SSCI 2016 Submission Web Site (http://ssci2016.cs.surrey.ac.uk/Paper%20Submission.htm).\r\n\r\n### Getting Started with BMOBench\r\n\r\n* Please refer to the guidelines given [here](https://github.com/ash-aldujaili/BMOBench).\r\n\r\n### References\r\n\r\n1. A. Al-Dujaili and S. Suresh, “**[BMOBench: Black-box multiobjective optimization benchmarking platform,](http://arxiv.org/pdf/1605.07009v1.pdf)**” *ArXiv e-prints*, vol.\r\narXiv:1605.07009, 2016.\r\n\r\n2. Custódio, Ana Luísa, et al. \"**[Direct multisearch for multiobjective optimization.](http://www.mat.uc.pt/~lnv/papers/dms.pdf)**\" *SIAM Journal on Optimization* 21.3 (2011): 1109-1140.\r\n\r\n3. Brockhoff, Dimo, Thanh-Do Tran, and Nikolaus Hansen. \"**[Benchmarking numerical multiobjective optimizers revisited.](https://hal.inria.fr/hal-01146741/document)**\" *Genetic and Evolutionary Computation Conference (GECCO 2015)*. 2015.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}